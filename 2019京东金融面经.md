# 2019京东面经

1、总体说一下集合框架

    Collection 
        List Set Queue Map

2、你怎么看待接口和抽象类

3、索引的分类

 *  从数据结构上来划分：Hash索引，BTree索引（B-Tree或B+Tree索引）  
    描述的是索引存储时保存的形式
 * 从应用层次来分：普通索引，唯一索引，复合索引。  
     • 普通索引：即一个索引只包含单个列，一个表可以有多个单列索引  
     • 唯一索引：索引列的值必须唯一，但允许有空值  
     • 复合索引：即一个索引包含多个列  
 * 根据中数据的物理顺序与键值的逻辑（索引）顺序关系：聚集索引，非聚集索引。  
    聚簇索引(聚集索引)：并不是一种单独的索引类型，而是一种数据存储方式。具体细节取决于不同的实现，InnoDB的聚簇索引其实就是在同一个结构中保存了B-Tree索引(技术上来说是B+Tree)和数据行。  
    非聚簇索引：不是聚簇索引，就是非聚簇索引

4、主键索引的设计应该采用B-tree索引还是hash索引

（1）Hash 索引仅仅能满足"=","IN"和"<=>"查询，不能使用范围查询。
     由于 Hash 索引比较的是进行 Hash 运算之后的 Hash 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样。

（2）Hash 索引无法被用来避免数据的排序操作。
     由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算；

（3）Hash 索引不能利用部分索引键查询。
     对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。

（4）Hash 索引在任何时候都不能避免表扫描。
     前面已经知道，Hash 索引是将索引键通过 Hash 运算之后，将 Hash运算结果的 Hash 值和所对应的行指针信息存放于一个 Hash 表中，由于不同索引键存在相同 Hash 值，所以即使取满足某个 Hash 键值的数据的记录条数，也无法从 Hash 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。

（5）Hash 索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。
     对于选择性比较低的索引键，如果创建 Hash 索引，那么将会存在大量记录指针信息存于同一个 Hash 值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下

 （6）B-Tree 索引是 MySQL 数据库中使用最为频繁的索引类型，除了 Archive 存储引擎之外的其他所有的存储引擎都支持 B-Tree 索引。不仅仅在 MySQL 中是如此，实际上在其他的很多数据库管理系统中B-Tree 索引也同样是作为最主要的索引类型，这主要是因为 B-Tree 索引的存储结构在数据库的数据检
索中有非常优异的表现。
      一般来说， MySQL 中的 B-Tree 索引的物理文件大多都是以 Balance Tree 的结构来存储的，也就 是所有实际需要的数据都存放于 Tree 的 Leaf Node ，而且到任何一个 Leaf Node 的最短路径的长度都是完全相同的，所以我们大家都称之为 B-Tree 索引当然，可能各种数据库（或 MySQL 的各种存储引擎）在存放自己的 B-Tree 索引的时候会对存储结构稍作改造。如 Innodb 存储引擎的 B-Tree 索引实际使用的存储结构实际上是 B+Tree ，也就是在 B-Tree 数据结构的基础上做了很小的改造，在每一个
Leaf Node 上面出了存放索引键的相关信息之外，还存储了指向与该 Leaf Node 相邻的后一个 LeafNode 的指针信息，这主要是为了加快检索多个相邻 Leaf Node 的效率考虑。
      在 Innodb 存储引擎中，存在两种不同形式的索引，一种是 Cluster 形式的主键索引（ Primary Key ），另外一种则是和其他存储引擎（如 MyISAM 存储引擎）存放形式基本相同的普通 B-Tree 索引，这种索引在 Innodb 存储引擎中被称为 Secondary Index 。下面我们通过图示来针对这两种索引的存放
形式做一个比较。


5、设计模式	

6、谈一谈DDD面向领域编程

7、说一下hibernate一级缓存和二级缓存

8、说一下你了解的MQ	

9、谈一谈你对高并发的理解，你会从什么角度设计高并发程序	

10、JUC包里的限流该怎么做到
    使用Semaphore 
   <https://www.cnblogs.com/itsoku123/p/11223837.html>

11、索引不适用的条件
在索引列上做任何操作(计算、函数、(自动 or 手动)类型转换)，会导致索引失效而转向全表扫描。因此，不要在索引列上做任何函数计算
使用 (!= 、<、>) 的时候，会导致索引失效
like 的前后模糊匹配
字段的 is not null 和 is null
索引列上不能有范围查询，将可能做范围查询的索引字段尽量放最后

mysql 索引优化：
   * 关联表查询优化 
       left join 在优化关联查询时，只有在被驱动表上建立索引才有效！ 
   在优化关联查询时，要使用小表(驱动表)驱动大表(被驱动表)，这样效率更高 left join 时，左侧的为驱动表，右侧为被驱动表；类比得出， right join 时，左侧为被驱动表；
   * inner join 时，mysql 会自己帮你把小结果集的表选为驱动表。
   * not in 优化
   结论：在范围判断时，尽量不要使用 not in 和 not exists，使用 left join on xxx is null 代替
   * 使用覆盖索引
   * 排序建索引，排序字段顺序和索引保持一样顺序，不能乱
   * group by 使用索引的原则基本与 order by 一致
   * using filesort 原理
     >mysql 的排序算法
     >> * 双路排序  
        MySQL 4.1 之前是使用双路排序，字面意思就是两次扫描磁盘，最终得到数据，读取行指针和 order by 列，对他们进行排序，然后扫描已经排序好的列表，按照列表中的值重新从列表中读取对应的数据输出。 从磁盘取排序字段，在 buffer 进行排序，再从磁盘取其他字段。 简单来说，取一批数据，要对磁盘进行了两次扫描，众所周知，I\O 是很耗时的，所以在 mysql4.1 之后，出现了第二种改进的算法，就是单路排序。
     >> * 单路排序  
     从磁盘读取查询需要的所有列，按照 order by 列在 buffer 对它们进行排序，然后扫描排序后的列表进行输出， 它的效率更快一些，避免了第二次读取数据。并且把随机 IO 变成了顺序 IO,但是它会使用更多的空间， 因为它把每一行都保存在内存中了。
     单路排序的问题
     由于单路是后出的，总体而言好过双路。但是存在以下问题:
     在 sort_buffer 中，方法 B 比方法 A 要多占用很多空间，因为方法 B 是把所有字段都取出, 所以有可能取出的数据的总大小超出了 sort_buffer 的容量，导致每次只能取 sort_buffer 容量大小的数据，进行排序(创建 tmp 文件，多路合并)，排完再取取 sort_buffer 容量大小，再排......从而多次 I/O。
     结论：本来想省一次 I/O 操作，反而导致了大量的 I/O 操作，反而得不偿失   
     >> * 如何优化
     >> * 增大 sort_butter_size 参数的设置  
     不管用哪种算法，提高这个参数都会提高效率，当然，要根据系统的能力去提高，因为这个参数是针对每个进程 1M-8M 之间调整
     >> * 增大 max_length_for_sort_data 参数的设置  
     mysql 使用单路排序的前提是排序的字段大小要小于 max_length_for_sort_data。 提高这个参数，会增加用改进算法的概率。但是如果设的太高，数据总容量超出 sort_buffer_size 的概率就增大，明显症状是高的磁盘 I/O 活动和低的处理器使用率。(1024-8192 之间调整)。
     >> * 减少 select 后面的查询的字段。  
     当 Query 的字段大小总和小于 max_length_for_sort_data 而且排序字段不是 TEXT|BLOB 类型时，会用改进后的算法——单路排序， 否则用老算法——多路排序。两种算法的数据都有可能超出 sort_buffer 的容量，超出之后，会创建 tmp 文件进行合并排序，导致多次 I/O，
     但是用单路排序算法的风险会更大一些，所以要提高 sort_buffer_size。  
                                               
12、说一下NIO和AIO


13、AIO里用到什么设计模式

14、说一下select，poll，epoll

15、谈一下TCP的拥塞控制

16、你知道什么是as-if-serial语义吗，它和happen-before语义有什么区别

17、Executors创建线程池的方式

18、CachedThreadPool里面用的什么阻塞队列  
* SynchronousQueue 队列长度为0 不像ArrayBlockingQueue、LinkedBlockingDeque之类的阻塞队列依赖AQS实现并发操作，SynchronousQueue直接使用CAS实现线程的安全访问  
没有缓存数据，SynchronousQueue 队列中没有任何缓存的数据，可以理解为容量为 0。我们可以尝试往队列中加入元素，然后调用 size() 方法发现不管怎么加入都是 0。
* SynchronousQueue 提供两种实现方式，分别是 栈 和 队列 的方式实现。这两种实现方式中，栈 是属于非公平的策略，队列 是属于公平策略。

19、那你知道LinkedTransferQueue吗，和SynchronousQueue有什么区别

20、你还知道什么阻塞队列，能具体说说它们的特点吗

阻塞队列 生产、消费模型，提供阻塞方法 put take
https://www.cnblogs.com/wade-luffy/p/5771052.html
* ArrayBlockingQueue和LinkedBlockingQueue是两个最普通也是最常用的阻塞队列，一般情况下，在处理多线程间的生产者消费者问题，使用这两个类足以。

* DelayQueue, （延期阻塞队列）（阻塞队列实现了BlockingQueue接口）

* ArrayBlockingQueue, （基于数组的并发阻塞队列） 底层是数组，有界队列，如果我们要使用生产者-消费者模式，这是非常好的选择。

* LinkedBlockingQueue, （基于链表的FIFO阻塞队列）  底层是链表，可以当做无界和有界队列来使用，所以大家不要以为它就是无界队列。

* LinkedBlockingDeque, （基于链表的FIFO双端阻塞队列）

* PriorityBlockingQueue, （带优先级的无界阻塞队列） 是无界队列，基于数组，数据结构为二叉堆，数组第一个也是树的根节点总是最小值。

* SynchronousQueue （并发同步阻塞队列）本身不带有空间来存储任何元素，使用上可以选择公平模式和非公平模式。

非阻塞队列
* ArrayDeque, （数组双端队列）

* PriorityQueue, （优先级队列）

* ConcurrentLinkedQueue, （基于链表的并发队列）
21、线程池的线程数怎么设置比较好  

* CPU 密集型任务：
比如像加解密，压缩、计算等一系列需要大量耗费 CPU 资源的任务，大部分场景下都是纯 CPU 计算。
* IO 密集型任务：
比如像 MySQL 数据库、文件的读写、网络通信等任务，这类任务不会特别消耗 CPU 资源，但是 IO 操作比较耗时，会占用比较多时间。

    1、CPU密集型：操作内存处理的业务，一般线程数设置为：CPU核数 + 1 或者 CPU核数*2。核数为4的话，一般设置 5 或 8

    2、IO密集型：文件操作，网络操作，数据库操作，一般线程设置为：cpu核数 / (1-0.9)，核数为4的话，一般设置 40
       
公式:
   
    线程数 = CPU 核心数 / (1 - 阻塞系数)
    线程数 = CPU 核心数 * (1 + IO 耗时/ CPU 耗时)

22、你知道新出的LongAdder吗，和AtomicLong有什么区别

回顾AtomicLong
AtomicLong是通过CAS(即Compare And Swap)原理来完成原子递增递减操作，在并发情况下不会出现线程不安全结果。AtomicLong中的value是使用volatile修饰，并发下各个线程对value最新值均可见。我们以incrementAndGet()方法来深入。

 	 public final long incrementAndGet() {
        return unsafe.getAndAddLong(this, valueOffset, 1L) + 1L;
    }

这里是调用了unsafe的方法

    public final long getAndAddLong(Object var1, long var2, long var4) {
        long var6;
        do {
            var6 = this.getLongVolatile(var1, var2);
        } while(!this.compareAndSwapLong(var1, var2, var6, var6 + var4));

        return var6;
    }

方法中this.compareAndSwapLong()有4个参数，var1是需要修改的类对象，var2是需要修改的字段的内存地址，var6是修改前字段的值，var6+var4是修改后字段的值。compareAndSwapLong只有该字段实际值和var6值相当的时候，才可以成功设置其为var6+var4。



再继续往深一层去看

public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6);
1
这里Unsafe.compareAndSwapLong是native方法，底层通过JNI(Java Native Interface)来完成调用，实际就是借助C来调用CPU指令来完成。

实现中使用了do-while循环，如果CAS失败，则会继续重试，直到成功为止。并发特别高的时候，虽然这里可能会有很多次循环，但是还是可以保证线程安全的。不过如果自旋CAS操作长时间不成功，竞争较大，会带CPU带来极大的开销，占用更多的执行资源，可能会影响其他主业务的计算等。

LongAdder怎么优化AtomicLong
Doug Lea在jdk1.5的时候就针对HashMap进行了线程安全和并发性能的优化，推出了分段锁实现的ConcurrentHashMap。一般Java面试，基本上离不开ConcurrentHashMap这个网红问题。另外在ForkJoinPool中，Doug Lea在其工作窃取算法上对WorkQueue使用了细粒度锁来较少并发的竞争,更多细节可参考我的原创文章ForkJoin使用和原理剖析。如果已经对ConcurrentHashMap有了较为深刻的理解，那么现在来看LongAdder的实现就会相对简单了。

来看LongAdder的increase()方法实现，

    public void add(long x) {
        Cell[] as; long b, v; int m; Cell a;
        //第一个if进行了两个判断，(1)如果cells不为空，则直接进入第二个if语句中。(2)同样会先使用cas指令来尝试add，如果成功则直接返回。如果失败则说明存在竞争，需要重新add
        if ((as = cells) != null || !casBase(b = base, b + x)) {
            boolean uncontended = true;
            if (as == null || (m = as.length - 1) < 0 ||
                (a = as[getProbe() & m]) == null ||
                !(uncontended = a.cas(v = a.value, v + x)))
                longAccumulate(x, null, uncontended);
        }
    }

这里用到了Cell类对象，Cell对象是LongAdder高并发实现的关键。在casBase冲突严重的时候，就会去创建Cell对象并添加到cells中，下面会详细分析。

    @sun.misc.Contended static final class Cell {
        volatile long value;
        Cell(long x) { value = x; }
        //提供CAS方法修改当前Cell对象上的value
        final boolean cas(long cmp, long val) {
            return UNSAFE.compareAndSwapLong(this, valueOffset, cmp, val);
        }

        // Unsafe mechanics
        private static final sun.misc.Unsafe UNSAFE;
        private static final long valueOffset;
        static {
            try {
                UNSAFE = sun.misc.Unsafe.getUnsafe();
                Class<?> ak = Cell.class;
                valueOffset = UNSAFE.objectFieldOffset
                    (ak.getDeclaredField("value"));
            } catch (Exception e) {
                throw new Error(e);
            }
        }
    }

而这一句a = as[getProbe() & m]其实就是通过getProbe()拿到当前Thread的threadLocalRandomProbe的probe Hash值。这个值其实是一个随机值，这个随机值由当前线程ThreadLocalRandom.current()产生。不用Rondom的原因是因为这里已经是高并发了，多线程情况下Rondom会极大可能得到同一个随机值。因此这里使用threadLocalRandomProbe在高并发时会更加随机，减少冲突。更多ThreadLocalRandom信息想要深入了解可关注这篇文章并发包中ThreadLocalRandom类原理浅尝。拿到as数组中当前线程的Cell对象，然后再进行CAS的更新操作,我们在源码上进行分析。longAccumulate()是在父类Striped64.java中。




    final void longAccumulate(long x, LongBinaryOperator fn,
                              boolean wasUncontended) {
        int h;
        if ((h = getProbe()) == 0) {
        	  //如果当前线程的随机数为0，则初始化随机数
            ThreadLocalRandom.current(); // force initialization
            h = getProbe();
            wasUncontended = true;
        }
        boolean collide = false;                // True if last slot nonempty
        for (;;) {
            Cell[] as; Cell a; int n; long v;
            //如果当前cells数组不为空
            if ((as = cells) != null && (n = as.length) > 0) {
            		//如果线程随机数对应的cells对应数组下标的Cell元素不为空，
                if ((a = as[(n - 1) & h]) == null) {
                		//当使用到LongAdder的Cell数组相关的操作时，需要先获取全局的cellsBusy的锁，才可以进行相关操作。如果当前有其他线程的使用，则放弃这一步，继续for循环重试。
                    if (cellsBusy == 0) {       // Try to attach new Cell
                    	//Cell的初始值是x，创建完毕则说明已经加上
                        Cell r = new Cell(x);   // Optimistically create
                        //casCellsBusy获取锁，cellsBusy通过CAS方式获取锁，当成功设置cellsBusy为1时，则获取到锁。
                        if (cellsBusy == 0 && casCellsBusy()) {
                            boolean created = false;
                            try {               // Recheck under lock
                                Cell[] rs; int m, j;
                                if ((rs = cells) != null &&
                                    (m = rs.length) > 0 &&
                                    rs[j = (m - 1) & h] == null) {
                                    rs[j] = r;
                                    created = true;
                                }
                            } finally {
                            	  //finally里面释放锁
                                cellsBusy = 0;
                            }
                            if (created)
                                break;
                            continue;           // Slot is now non-empty
                        }
                    }
                    collide = false;
                }
                else if (!wasUncontended)       // CAS already known to fail
                    wasUncontended = true;      // Continue after rehash
                //如果a不为空，则对a进行cas增x操作，成功则返回    
                else if (a.cas(v = a.value, ((fn == null) ? v + x :
                                             fn.applyAsLong(v, x))))
                    break;
                //cells的长度n已经大于CPU数量，则继续扩容没有意义，因此直接标记为不冲突
                else if (n >= NCPU || cells != as)
                    collide = false;            // At max size or stale
                else if (!collide)
                    collide = true;
                //到这一步则说明a不为空但是a上进行CAS操作也有多个线程在竞争，因此需要扩容cells数组，其长度为原长度的2倍
                else if (cellsBusy == 0 && casCellsBusy()) {
                    try {
                        if (cells == as) {      // Expand table unless stale
                            Cell[] rs = new Cell[n << 1];
                            for (int i = 0; i < n; ++i)
                                rs[i] = as[i];
                            cells = rs;
                        }
                    } finally {
                        cellsBusy = 0;
                    }
                    collide = false;
                    continue;                   // Retry with expanded table
                }
                //继续使用新的随机数，避免在同一个Cell上竞争
                h = advanceProbe(h);
            }
            //如果cells为空，则需要先创建Cell数组。初始长度为2.(个人理解这个if放在前面会比较好一点，哈哈)
            else if (cellsBusy == 0 && cells == as && casCellsBusy()) {
                boolean init = false;
                try {                           // Initialize table
                    if (cells == as) {
                        Cell[] rs = new Cell[2];
                        rs[h & 1] = new Cell(x);
                        cells = rs;
                        init = true;
                    }
                } finally {
                    cellsBusy = 0;
                }
                if (init)
                    break;
            }
            //如果在a上竞争失败，且扩容竞争也失败了，则在casBase上尝试增加数量
            else if (casBase(v = base, ((fn == null) ? v + x :
                                        fn.applyAsLong(v, x))))
                break;                          // Fall back on using base
        }
    }
    

最后是求LongAdder的总数，这一步就非常简单了，把base的值和所有cells上的value值加起来就是总数了。

    public long sum() {
        Cell[] as = cells; Cell a;
        long sum = base;
        if (as != null) {
            for (int i = 0; i < as.length; ++i) {
                if ((a = as[i]) != null)
                    sum += a.value;
            }
        }
        return sum;
    }

思考
源码中Cell数组的会控制在不超过NCPU的两倍，原因是LongAdder其实在底层是依赖CPU的CAS指令来操作，如果多出太多，即使在代码层面没有竞争，在底层CPU的竞争会更多，所以这里会有一个数量的限制。所以在LongAdder的设计中，由于使用到CAS指令操作，瓶颈在于CPU上。

YY一下，那么有没有方式可以突破这个瓶颈呢？我个人觉得是有的，但是有前提条件，应用场景极其有限。基于ThreadLocal的设计，假设统计只在一个固定的线程池中进行，假设线程池中的线程不会销毁(异常补充线程的就暂时不管了)，则可以认为线程数量是固定且不变的，那么统计则可以依赖于只在当前线程中进行，那么即使是高并发，就转化为ThreadLocal这种单线程操作了，完全可以摆脱CAS的CPU指令操作的限制，那么性能将极大提升。

总结
在并发处理上，AtomicLong和LongAdder均具有各自优势，需要怎么使用还是得看使用场景。看完这篇文章，其实并不意味着LongAdder就一定比AtomicLong好使，个人认为在QPS统计等统计操作上，LongAdder会更加适合，而AtomicLong在自增控制方面是LongAdder无法代替的。在多数地并发和少数高并发情况下，AtomicLong和LongAdder性能上差异并不是很大，只有在并发极高的时候，才能真正体现LongAdder的优势。


23、那你知道LongAccumulator吗


Java并发编程笔记之LongAdder和LongAccumulator源码探究
一.LongAdder原理
LongAdder类是JDK1.8新增的一个原子性操作类。AtomicLong通过CAS算法提供了非阻塞的原子性操作，相比受用阻塞算法的同步器来说性能已经很好了，但是JDK开发组并不满足于此，因为非常搞并发的请求下AtomicLong的性能是不能让人接受的。

如下AtomicLong 的incrementAndGet的代码，虽然AtomicLong使用CAS算法，但是CAS失败后还是通过无限循环的自旋锁不多的尝试，这就是高并发下CAS性能低下的原因所在。源码如下：


　　public final long incrementAndGet() {
        for (;;) {
            long current = get();
            long next = current + 1;
            if (compareAndSet(current, next))
                return next;
        }
    }

在高并发下N多线程同时去操作一个变量会造成大量线程CAS失败，然后处于自旋状态，这样导致大大浪费CPU资源，降低了并发性。

既然AtomicLong性能问题是由于过多线程同时去竞争同一个变量的更新而降低的，那么如果把一个变量分解为多个变量，让同样多的线程去竞争多个资源，那么性能问题不久迎刃而解了吗？

没错，因此，JDK8 提供的LongAdder就是这个思路。下面通过图形来标示两者的不同，如下图：



如上图 AtomicLong 是多个线程同时竞争同一个变量情景。



如上图所示，LongAdder则是内部维护多个Cell变量，每个Cell里面有一个初始值为0的long型变量，在同等并发量的情况下，争夺单个变量的线程会减少，这是变相的减少了争夺共享资源的并发量，另外多个线程在争夺同一个原子变量时候，

如果失败并不是自旋CAS重试，而是尝试获取其他原子变量的锁，最后当获取当前值时候是把所有变量的值累加后再加上base的值返回的。

 

LongAdder维护了要给延迟初始化的原子性更新数组和一个基值变量base数组的大小保持是2的N次方大小，数组表的下标使用每个线程的hashcode值的掩码表示，数组里面的变量实体是Cell类型。

Cell 类型是Atomic的一个改进，用来减少缓存的争用，对于大多数原子操作字节填充是浪费的，因为原子操作都是无规律的分散在内存中进行的，多个原子性操作彼此之间是没有接触的，但是原子性数组元素彼此相邻存放将能经常共享缓存行，也就是伪共享。所以这在性能上是一个提升。

另外由于Cells占用内存是相对比较大的，所以一开始并不创建，而是在需要时候再创建，也就是惰性加载，当一开始没有空间时候，所有的更新都是操作base变量。

 

接下来进行LongAdder代码简单分析

这里我只是简单的介绍一下代码的实现，详细实现，大家可以翻看代码去研究。为了降低高并发下多线程对一个变量CAS争夺失败后大量线程会自旋而造成降低并发性能问题，LongAdder内部通过根据并发请求量来维护多个Cell元素(一个动态的Cell数组)来分担对单个变量进行争夺资源。

首先我们先看LongAdder的构造类图，如下图：



 

 可以看到LongAdder继承自Striped64类，Striped64内部维护着三个变量，LongAdder的真实值其实就是base的值与Cell数组里面所有Cell元素值的累加，base是个基础值，默认是0，cellBusy用来实现自旋锁，当创建Cell元素或者扩容Cell数组时候用来进行线程间的同步。

 

接下来进去源码如看Cell的构造，源码如下：


　　@sun.misc.Contended static final class Cell {
        volatile long value;
        Cell(long x) { value = x; }
        final boolean cas(long cmp, long val) {
            return UNSAFE.compareAndSwapLong(this, valueOffset, cmp, val);
        }

        // Unsafe 技术
        private static final sun.misc.Unsafe UNSAFE;
        private static final long valueOffset;
        static {
            try {
                UNSAFE = sun.misc.Unsafe.getUnsafe();
                Class<?> ak = Cell.class;
                valueOffset = UNSAFE.objectFieldOffset
                    (ak.getDeclaredField("value"));
            } catch (Exception e) {
                throw new Error(e);
            }
        }
    }

正如上面的代码可以知道Cell的构造很简单，内部维护一个声明volatile的变量，这里声明为volatile是因为线程操作value变量时候没有使用锁，为了保证变量的内存可见性这里只有声明为volatile。另外这里就是先前文件所说的使用Unsafe类的方法来设置value的值

 

接下来进入LongAdder的源码里面去看几个重要的方法，如下：

　　1.long sum() 方法：返回当前的值，内部操作是累加所有 Cell 内部的 value 的值后累加 base，如下代码，由于计算总和时候没有对 Cell 数组进行加锁，所以在累加过程中可能有其它线程对 Cell 中的值进行了修改，也有可能数组进行了扩容，所以 sum 返回的值并不是非常精确的，

返回值并不是一个调用 sum 方法时候的一个原子快照值。

　　源码如下：

　　

public long sum() {
        Cell[] as = cells; Cell a;
        long sum = base;
        if (as != null) {
            for (int i = 0; i < as.length; ++i) {
                if ((a = as[i]) != null)
                    sum += a.value;
            }
        }
        return sum;
}

 

　　2.void reset() 方法：重置操作，如下代码把 base 置为 0，如果 Cell 数组有元素，则元素值重置为 0。源码如下：

　　
　　public void reset() {
        Cell[] as = cells; Cell a;
        base = 0L;
        if (as != null) {
            for (int i = 0; i < as.length; ++i) {
                if ((a = as[i]) != null)
                    a.value = 0L;
            }
        }
   }


　　3.long sumThenReset() 方法：是sum 的改造版本，如下代码，在计算 sum 累加对应的 cell 值后，把当前 cell 的值重置为 0，base 重置为 0。 当多线程调用该方法时候会有问题，比如考虑第一个调用线程会清空 Cell 的值，后一个线程调用时候累加时候累加的都是 0 值。

　　源码如下：


　　public long sumThenReset() {
        Cell[] as = cells; Cell a;
        long sum = base;
        base = 0L;
        if (as != null) {
            for (int i = 0; i < as.length; ++i) {
                if ((a = as[i]) != null) {
                    sum += a.value;
                    a.value = 0L;
                }
            }
        }
        return sum;
    }

 
　　4.long longValue() 等价于 sum()，源码如下：

　　

    public long longValue() {
        return this.sum();
    }
 

　　5.void add(long x） 累加增量 x 到原子变量，这个过程是原子性的。源码如下：

　　
　　public void add(long x) {
        Cell[] as; long b, v; int m; Cell a;
        if ((as = cells) != null || !casBase(b = base, b + x)) {//(1)
            boolean uncontended = true;
            if (as == null || (m = as.length - 1) < 0 ||//(2)
                (a = as[getProbe() & m]) == null ||//(3)
                !(uncontended = a.cas(v = a.value, v + x)))//(4)
                longAccumulate(x, null, uncontended);//(5)
        }
    }

    final boolean casBase(long cmp, long val) {
        return UNSAFE.compareAndSwapLong(this, BASE, cmp, val);
    }

可以看到上面代码，当第一个线程A执行add时候，代码（1）会执行casBase方法，通过CAS设置base为 X， 如果成功则直接返回，这时候base的值为1。

假如多个线程同时执行add时候，同时执行到casBase则只有一个线程A成功返回，其他线程由于CAS失败执行代码（2），代码（2）是获取cells数组的长度，如果数组长度为0，则执行代码（5），否则cells长度不为0，说明cells数组有元素则执行代码（3），

代码（3）首先计算当前线程在数组中下标，然后获取当前线程对应的cell值，如果获取到则执行（4）进行CAS操作，CAS失败则执行代码（5）。

代码（5）里面是具体进行数组扩充和初始化，这个代码比较复杂，这里就不讲解了，有兴趣的可以进去看看。

 

二.LongAccumulator类源码分析
LongAdder类是LongAccumulator的一个特例，LongAccumulator提供了比LongAdder更强大的功能，如下构造函数，其中accumulatorFunction是一个双目运算器接口，根据输入的两个参数返回一个计算值，identity则是LongAccumulator累加器的初始值。

public LongAccumulator(LongBinaryOperator accumulatorFunction,long identity) {
        this.function = accumulatorFunction;
        base = this.identity = identity;
}
public interface LongBinaryOperator {

       //根据两个参数计算返回一个值
       long applyAsLong(long left, long right);
}

上面提到LongAdder 其实就是LongAccumulator 的一个特例，调用LongAdder 相当使用下面的方式调用 LongAccumulator。


　　 LongAdder adder = new LongAdder();
    LongAccumulator accumulator = new LongAccumulator(new LongBinaryOperator() {

        @Override
        public long applyAsLong(long left, long right) {
            return left + right;
        }
    }, 0);

LongAccumulator相比LongAdder 可以提供累加器初始非0值，后者只能默认为0，另外前者还可以指定累加规则，比如不是累加而相乘，只需要构造LongAccumulator 时候传入自定义双目运算器即可，后者则内置累加规则。

 

从下面代码知道LongAccumulator相比于LongAdde的不同在于casBase的时候，后者传递的是b+x,而前者则是调用了r=function.applyAsLong(b=base.x)来计算。

LongAdder类的add源码如下：

　　public void add(long x) {
        Cell[] as; long b, v; int m; Cell a;
        if ((as = cells) != null || !casBase(b = base, b + x)) {
            boolean uncontended = true;
            if (as == null || (m = as.length - 1) < 0 ||
                (a = as[getProbe() & m]) == null ||
                !(uncontended = a.cas(v = a.value, v + x)))
                longAccumulate(x, null, uncontended);
        }
    }


LongAccumulator的accumulate方法的源码如下：

复制代码
　　public void accumulate(long x) {
        Cell[] as; long b, v, r; int m; Cell a;
        if ((as = cells) != null ||
            (r = function.applyAsLong(b = base, x)) != b && !casBase(b, r)) {
            boolean uncontended = true;
            if (as == null || (m = as.length - 1) < 0 ||
                (a = as[getProbe() & m]) == null ||
                !(uncontended =
                  (r = function.applyAsLong(v = a.value, x)) == v ||
                  a.cas(v, r)))
                longAccumulate(x, function, uncontended);
        }
    }
复制代码
 

另外LongAccumulator调用longAccumulate时候传递的是function,而LongAdder是null,从下面代码可以知道当fn为null，时候就是使用v+x  加法运算，这时候就等价于LongAdder,fn不为null的时候则使用传递的fn函数计算，如果fn为加法则等价于LongAdder;

else if (casBase(v = base, ((fn == null) ? v + x :fn.applyAsLong(v, x))))
    　　　// Fall back on using base
　　　　　　break;

